{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import BeautifulSoup for HTML parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup   #Use Metis Kernal\n",
    "import requests\n",
    "import time, os\n",
    "import itertools\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webdriver stuff setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open chromedriver window thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)    #Do not rerun everytime, this opens a new window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://boardgamegeek.com/browse/boardgame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_game_url = 'https://boardgamegeek.com/browse/boardgame' \n",
    "\n",
    "response = requests.get(board_game_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landing_url_list = []\n",
    "\n",
    "for i in range(1,31):\n",
    "    landing_url_list.append('https://boardgamegeek.com/browse/boardgame'+'/page/'+str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://boardgamegeek.com/browse/boardgame/page/1',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/2',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/3',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/4',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/5',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/6',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/7',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/8',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/9',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/10',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/11',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/12',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/13',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/14',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/15',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/16',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/17',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/18',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/19',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/20',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/21',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/22',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/23',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/24',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/25',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/26',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/27',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/28',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/29',\n",
       " 'https://boardgamegeek.com/browse/boardgame/page/30']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landing_url_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing 30 landing pages. Run once!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium_landing_list_30 = []\n",
    "\n",
    "# for url in landing_url_list:\n",
    "#     driver.get(url)\n",
    "#     selenium_landing_list_30.append(BeautifulSoup(driver.page_source, 'html.parser'))\n",
    "    \n",
    "    \n",
    "#     time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "print(type(selenium_landing_list_30[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sel_30_num1.html\", \"w\") as file:\n",
    "    file.write(str(selenium_landing_list_30[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(selenium_landing_list_30[0].find_all( id='row_')) # matches, all good!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull URL info into Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(board_game_url) #only run once per time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.page_source[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "selenium_soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(selenium_soup.find_all( id='row_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{e['class_=\"collection_rank\"'] : e.text.strip() for e in soup1.find_all(attrs={'class_':True})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_landing_page = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(bg_landing_page, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #every request\n",
    "# import time\n",
    "\n",
    "# page_list = ['page1','page2','page3']\n",
    "\n",
    "# for page in page_list:\n",
    "#     ### scrape a website\n",
    "#     ### ...\n",
    "#     print(page)\n",
    "    \n",
    "#     time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gloomhaven', '(2017)')\n"
     ]
    }
   ],
   "source": [
    "gloom = tuple(selenium_soup.find(id=\"CEcell_objectname1\").text.split())\n",
    "print(tuple(selenium_soup.find(id=\"CEcell_objectname1\").text.split()[:2]))\n",
    "\n",
    "# gloom_list = gloom.split()\n",
    "# print(gloom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are 100 id=\"row_\" per page!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,ele in enumerate(selenium_soup.find_all(id=\"row_\")[:7]):\n",
    "#     print(i, ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [link.text for link in soup1.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for getting 100 games per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_100 = list(range(1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(selenium_soup.find_all(\"span\", class_=\"positive\"))\n",
    "for i,price in enumerate(selenium_soup.find_all(id=\"row\")):\n",
    "    if price.find(\"span\", class_=\"positive\"):\n",
    "        print(i, price.find(\"span\", class_=\"positive\").text)\n",
    "    else:\n",
    "        print(i, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working function for Rank, name, year, url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing geek rating, avg rating, num voters\n",
    "# soup1.find(id=\"row_\").find(class_=\"collection_bggrating\").text.strip()\n",
    "# soup1.find(id=\"row_\").find(class_=\"collection_bggrating\").findNext().text.strip()\n",
    "# soup1.find(id=\"row_\").find(class_=\"collection_bggrating\").findNext().findNext().text.strip()\n",
    "\n",
    "\n",
    "first_100 = [] #List of lists of lists: [rank, [Game Name, year]]\n",
    "direct_pages_100 = []\n",
    "\n",
    "# id=\"results_objectname\"+str(rank)).text.strip().split(\"\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\"),page.find(\n",
    "\n",
    "\n",
    "def get_100_per_page(page):\n",
    "    for rank in names_100:\n",
    "       first_100.append([rank,page.find(\n",
    "           id=\"results_objectname\"+str(rank)).text.strip().split(\"\\n\"),page.find(\n",
    "           id=\"results_objectname\"+str(rank)).find('a').get(\"href\")    #, float(page.find(\n",
    "           #id=\"row_\").find(class_=\"collection_bggrating\").text.strip()), float(page.find(\n",
    "           #id=\"row_\").find(class_=\"collection_bggrating\").findNext().text.strip()), int(page.find(\n",
    "           #id=\"row_\").find(class_=\"collection_bggrating\").findNext().findNext().text.strip())\n",
    "                        ]) \n",
    "       direct_pages_100.append(page.find(\n",
    "           id=\"results_objectname\"+str(rank)).find('a').get(\"href\"))\n",
    "\n",
    "get_100_per_page(selenium_soup)\n",
    "first_100_unpacked = []\n",
    "\n",
    "# print(first_100) # also need to add url to open specific page\n",
    "# print(direct_pages_100)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpacking list in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in first_100:\n",
    "    game.append(game[2])\n",
    "    game[2] = game[1][1]\n",
    "    game[1] = game[1][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'Gloomhaven', '(2017)', '/boardgame/174430/gloomhaven']\n",
      "[2, 'Pandemic Legacy: Season 1', '(2015)', '/boardgame/161936/pandemic-legacy-season-1']\n",
      "[3, 'Brass: Birmingham', '(2018)', '/boardgame/224517/brass-birmingham']\n",
      "[4, 'Terraforming Mars', '(2016)', '/boardgame/167791/terraforming-mars']\n",
      "[5, 'Gloomhaven: Jaws of the Lion', '(2020)', '/boardgame/291457/gloomhaven-jaws-lion']\n",
      "[6, 'Twilight Imperium: Fourth Edition', '(2017)', '/boardgame/233078/twilight-imperium-fourth-edition']\n"
     ]
    }
   ],
   "source": [
    "for item in first_100[:6]:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_100_df = pd.DataFrame(first_100, columns=([\"rank\", \"game\", \"year\", \"url\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_100_df\n",
    "merge_first_100_df = pd.concat([first_100_df, price_df], axis=1)\n",
    "# result = pd.merge(left, right, how=\"outer\", on=[\"key1\", \"key2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   rank    100 non-null    int64 \n",
      " 1   game    100 non-null    object\n",
      " 2   year    100 non-null    object\n",
      " 3   url     100 non-null    object\n",
      " 4   rank    100 non-null    object\n",
      " 5   store   97 non-null     object\n",
      " 6   price   97 non-null     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "merge_first_100_df.info()\n",
    "merge_first_100_df = pd.concat([merge_first_100_df, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to search by name=\"1,2,3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Rank, Vendor, price - Add to df after????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_vendor = []\n",
    "\n",
    "\n",
    "def game_prices_page(page):\n",
    "    for ele in page.find_all(id=\"row_\"):\n",
    "        try:\n",
    "            price_vendor.append([ele.find(\n",
    "                class_=\"collection_rank\").text.strip(), ele.find(\n",
    "                class_=\"ulprice\").text.split(\":\\xa0\")]) #this works!!!\n",
    "        except AttributeError:\n",
    "            price_vendor.append([ele.find(\n",
    "                class_=\"collection_rank\").text.strip(), [None, None]])\n",
    "        \n",
    "    \n",
    "\n",
    "game_prices_page(selenium_soup)\n",
    "\n",
    "#straighten out the list of lists of lists hahaha\n",
    "\n",
    "for game in price_vendor:\n",
    "    game.append(game[1])\n",
    "    game[2] = game[1][1]\n",
    "    game[1] = game[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal to join this as a df to the above one on rank-num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>store</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$101.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Geek Game Shop</td>\n",
       "      <td>$79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$89.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$49.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$34.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank           store    price\n",
       "0    1      New Amazon  $101.99\n",
       "1    2  Geek Game Shop   $79.99\n",
       "2    3      New Amazon   $89.95\n",
       "3    4      New Amazon   $49.31\n",
       "4    5      New Amazon   $34.93"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df = pd.DataFrame(price_vendor, columns=([\"rank\", \"store\", \"price\"]))\n",
    "price_vendor[:3]\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar function with geek ratings, user ratings, num votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "\n",
    "def game_ratings_page(page):\n",
    "    for ele in page.find_all(id=\"row_\"):\n",
    "        ratings.append([float(ele.find(\n",
    "            class_=\"collection_bggrating\").text.strip()), float(ele.find(\n",
    "            class_=\"collection_bggrating\").findNext().text.strip()), int(ele.find(\n",
    "            class_=\"collection_bggrating\").findNext().findNext().text.strip())])\n",
    "\n",
    "game_ratings_page(selenium_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[:7]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings, columns=[\"geek_rtg\", \"avg_rtg\", \"num_voters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## From this landing page I have: rank, name, year, geek_ratings, user_ratings, num_votes, vendor, price, *URL*\n",
    "\n",
    "### Use *URL* to get to each individual page ( /123456/gloomhaven/*stats*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'https://boardgamegeek.com/browse/boardgame/page/{\"1\", \"2\", \"3\", etc...}' # sleep sleep sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_first_100_df = pd.concat([merge_first_100_df, ratings_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First 100 in a dataframe!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>game</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>rank</th>\n",
       "      <th>store</th>\n",
       "      <th>price</th>\n",
       "      <th>geek_rtg</th>\n",
       "      <th>avg_rtg</th>\n",
       "      <th>num_voters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gloomhaven</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>/boardgame/174430/gloomhaven</td>\n",
       "      <td>1</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$101.99</td>\n",
       "      <td>8.528</td>\n",
       "      <td>8.76</td>\n",
       "      <td>45694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pandemic Legacy: Season 1</td>\n",
       "      <td>(2015)</td>\n",
       "      <td>/boardgame/161936/pandemic-legacy-season-1</td>\n",
       "      <td>2</td>\n",
       "      <td>Geek Game Shop</td>\n",
       "      <td>$79.99</td>\n",
       "      <td>8.452</td>\n",
       "      <td>8.60</td>\n",
       "      <td>43748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Brass: Birmingham</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>/boardgame/224517/brass-birmingham</td>\n",
       "      <td>3</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$89.95</td>\n",
       "      <td>8.409</td>\n",
       "      <td>8.67</td>\n",
       "      <td>23176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Terraforming Mars</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>/boardgame/167791/terraforming-mars</td>\n",
       "      <td>4</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$49.31</td>\n",
       "      <td>8.278</td>\n",
       "      <td>8.42</td>\n",
       "      <td>70574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gloomhaven: Jaws of the Lion</td>\n",
       "      <td>(2020)</td>\n",
       "      <td>/boardgame/291457/gloomhaven-jaws-lion</td>\n",
       "      <td>5</td>\n",
       "      <td>New Amazon</td>\n",
       "      <td>$34.93</td>\n",
       "      <td>8.260</td>\n",
       "      <td>8.74</td>\n",
       "      <td>13218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank                          game    year  \\\n",
       "0    1                    Gloomhaven  (2017)   \n",
       "1    2     Pandemic Legacy: Season 1  (2015)   \n",
       "2    3             Brass: Birmingham  (2018)   \n",
       "3    4             Terraforming Mars  (2016)   \n",
       "4    5  Gloomhaven: Jaws of the Lion  (2020)   \n",
       "\n",
       "                                          url rank           store    price  \\\n",
       "0                /boardgame/174430/gloomhaven    1      New Amazon  $101.99   \n",
       "1  /boardgame/161936/pandemic-legacy-season-1    2  Geek Game Shop   $79.99   \n",
       "2          /boardgame/224517/brass-birmingham    3      New Amazon   $89.95   \n",
       "3         /boardgame/167791/terraforming-mars    4      New Amazon   $49.31   \n",
       "4      /boardgame/291457/gloomhaven-jaws-lion    5      New Amazon   $34.93   \n",
       "\n",
       "   geek_rtg  avg_rtg  num_voters  \n",
       "0     8.528     8.76       45694  \n",
       "1     8.452     8.60       43748  \n",
       "2     8.409     8.67       23176  \n",
       "3     8.278     8.42       70574  \n",
       "4     8.260     8.74       13218  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_first_100_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Function for landing page of first 3000 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_3000 = []\n",
    "# url_3000 = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(selenium_landing_list_30) # 30 pages\n",
    "\n",
    "for html_page in selenium_landing_list_30:   #around 2 minutes to run\n",
    "    get_100_per_page(html_page)\n",
    "    game_prices_page(html_page)\n",
    "    game_ratings_page(html_page)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for game in first_3000:\n",
    "#     game.append(game[2])\n",
    "#     game[2] = game[1][1]\n",
    "#     game[1] = game[1][0]\n",
    "\n",
    "for game in price_3000:\n",
    "    game.append(game[1])\n",
    "    game[2] = game[1][1]\n",
    "    game[1] = game[1][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_3000 = [] #List of lists of lists: [rank, [Game Name, year]]\n",
    "url_3000 = []\n",
    "\n",
    "def get_100_per_page(page):\n",
    "    for rank in names_100:\n",
    "       first_3000.append([rank,page.find(\n",
    "           id=\"results_objectname\"+str(rank)).text.strip().split(\"\\n\"),page.find(\n",
    "           id=\"results_objectname\"+str(rank)).find('a').get(\"href\")    #, float(page.find(\n",
    "           #id=\"row_\").find(class_=\"collection_bggrating\").text.strip()), float(page.find(\n",
    "           #id=\"row_\").find(class_=\"collection_bggrating\").findNext().text.strip()), int(page.find(\n",
    "           #id=\"row_\").find(class_=\"collection_bggrating\").findNext().findNext().text.strip())\n",
    "                        ]) \n",
    "       url_3000.append(page.find(\n",
    "           id=\"results_objectname\"+str(rank)).find('a').get(\"href\"))\n",
    "\n",
    "# get_100_per_page(selenium_soup)\n",
    "# first_100_unpacked = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in first_3000:\n",
    "    game.append(game[2])\n",
    "    game[2] = game[1][1]\n",
    "    game[1] = game[1][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_df = pd.DataFrame(first_3000, columns=([\"rank\", \"game\", \"year\", \"url\"]))\n",
    "all_prices_df = pd.DataFrame(price_3000, columns=([\"rank\", \"store\", \"price\"]))\n",
    "all_ratings_df = pd.DataFrame(ratings_3000, columns=[\"geek_rtg\", \"avg_rtg\", \"num_voters\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_landing_df = pd.concat([all_names_df, all_prices_df, all_ratings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_df = pd.DataFrame(first_3000, columns=([\"rank\", \"game\", \"year\", \"url\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price_3000 = []\n",
    "\n",
    "def game_prices_page(page):\n",
    "    for ele in page.find_all(id=\"row_\"):\n",
    "        try:\n",
    "            price_3000.append([ele.find(\n",
    "                class_=\"collection_rank\").text.strip(), ele.find(\n",
    "                class_=\"ulprice\").text.split(\":\\xa0\")]) #this works!!!\n",
    "        except AttributeError:\n",
    "            price_3000.append([ele.find(\n",
    "                class_=\"collection_rank\").text.strip(), [None, None]])\n",
    "        \n",
    "    \n",
    "\n",
    "# game_prices_page(selenium_soup)\n",
    "\n",
    "#straighten out the list of lists of lists hahaha\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in price_3000:\n",
    "    game.append(game[1])\n",
    "    game[2] = game[1][1]\n",
    "    game[1] = game[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prices_df = pd.DataFrame(price_3000, columns=([\"rank\", \"store\", \"price\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_3000 = []\n",
    "\n",
    "def game_ratings_page(page):\n",
    "    for ele in page.find_all(id=\"row_\"):\n",
    "        ratings_3000.append([float(ele.find(\n",
    "            class_=\"collection_bggrating\").text.strip()), float(ele.find(\n",
    "            class_=\"collection_bggrating\").findNext().text.strip()), int(ele.find(\n",
    "            class_=\"collection_bggrating\").findNext().findNext().text.strip())])\n",
    "\n",
    "# game_ratings_page(selenium_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings_df = pd.DataFrame(ratings_3000, columns=[\"geek_rtg\", \"avg_rtg\", \"num_voters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_landing_df = pd.concat([all_names_df, all_prices_df, all_ratings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_landing_df['ranking'] = final_landing_df.index +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   rank        3000 non-null   int64  \n",
      " 1   game        3000 non-null   object \n",
      " 2   year        3000 non-null   object \n",
      " 3   url         1114 non-null   object \n",
      " 4   rank        3000 non-null   object \n",
      " 5   store       1738 non-null   object \n",
      " 6   price       1738 non-null   object \n",
      " 7   geek_rtg    3000 non-null   float64\n",
      " 8   avg_rtg     3000 non-null   float64\n",
      " 9   num_voters  3000 non-null   int64  \n",
      " 10  ranking     3000 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 257.9+ KB\n"
     ]
    }
   ],
   "source": [
    "final_landing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.to_csv('/Users/derekcall/metis/eda_project/new_mta_data_all.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_landing_df.to_csv ('/Users/derekcall/metis/linear_regression/landing_page_3000.csv', index = True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
